{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model uppercase characters and score NIST dataset\n",
    "    - Create a model only with uppercase charactes of the new character database. \n",
    "    - Evaluate it in a test partition\n",
    "    - Use the previous trained model to score the TICH test database (database only of uppercase characters)\n",
    "    - Use the previous trained model to score the uppercase characters of NIST test database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/jorge/data/tesis/handwriting/databases/unipen/'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import cv2\n",
    "\n",
    "from scipy.misc import imresize, imrotate, imsave \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# display plots in this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# set display defaults\n",
    "plt.rcParams['figure.figsize'] = (10, 10)        # large images\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # don't interpolate: show square pixels\n",
    "plt.rcParams['image.cmap'] = 'gray'              # use grayscale output color heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#Select the subset of characters\n",
    "#\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def prepare_data_char_subset(X, y, char_select):\n",
    "    '''\n",
    "    Definition: Create train test data to model it\n",
    "        - Select cases\n",
    "        - shuffle\n",
    "        - separate train test\n",
    "        - encode target to dummy vars\n",
    "    Parameters:\n",
    "        X: images[n_images, x_size, y_size]\n",
    "        y: characters[n_images, 1]\n",
    "        char_select: list of characters selected\n",
    "        augmentation_fuction\n",
    "    \n",
    "    usage:\n",
    "        prepare_data_char_subset(X, y, set(['1','0']), augmentation_fuction = lambda: augmentate01(param1, param2=p2) )\n",
    "        \n",
    "    return:\n",
    "        X_train, y_train, X_test, y_test, labels_dictionary\n",
    "    '''\n",
    "    #Select cases\n",
    "    X_select = []\n",
    "    y_select = []\n",
    "    for row in xrange(X.shape[0]):\n",
    "        if y[row] in set(char_select):\n",
    "            X_select += [X[row,:,:]]\n",
    "            y_select += y[row]\n",
    "    X_select = np.array(X_select, dtype = np.float16)\n",
    "    y_select = np.array(y_select)\n",
    "    print 'Shape of selected cases:', X_select.shape, y_select.shape\n",
    "    \n",
    "    \n",
    "    #Shuffle\n",
    "    X_select, y_select = shuffle(X_select, y_select, random_state=0)\n",
    "    \n",
    "    #Reescale\n",
    "    X_select = X_select/255.\n",
    "    \n",
    "    #Recode target\n",
    "    decode_target={}\n",
    "    encode_target={}\n",
    "    for i,c in enumerate(char_select):\n",
    "        decode_target[i] = c \n",
    "        encode_target[c] = i\n",
    "    y_select = np.array([encode_target[y] for y in y_select])\n",
    "    \n",
    "\n",
    "    #Separate train test\n",
    "    X_train, X_test, y_train_ini, y_test_ini = train_test_split(X_select, y_select, test_size=0.20, random_state=42)\n",
    "    X_train = np.reshape(X_train,  (X_train.shape[0],1,X_train.shape[1],X_train.shape[2]))\n",
    "    X_test = np.reshape(X_test,  (X_test.shape[0],1,X_test.shape[1],X_test.shape[2]))\n",
    "    \n",
    "    print 'Train shape: ',X_train.shape, y_train_ini.shape\n",
    "    print 'Test shape: ',X_test.shape, y_test_ini.shape\n",
    "    print 'Num classes: ', len(set(y_train_ini))\n",
    "    print 'Classes:', set(y_train_ini)\n",
    "    \n",
    "    return X_train, y_train_ini, X_test, y_test_ini, decode_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((46102, 64, 64), (46102,))\n",
      "Shape of selected cases: (16257, 64, 64) (16257,)\n",
      "Train shape:  (13005, 1, 64, 64) (13005,)\n",
      "Test shape:  (3252, 1, 64, 64) (3252,)\n",
      "Num classes:  26\n",
      "Classes: set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25])\n",
      "((13005, 1, 64, 64), (3252, 1, 64, 64))\n",
      "Shape of selected cases: (29845, 64, 64) (29845,)\n",
      "Train shape:  (23876, 1, 64, 64) (23876,)\n",
      "Test shape:  (5969, 1, 64, 64) (5969,)\n",
      "Num classes:  26\n",
      "Classes: set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25])\n",
      "((23876, 1, 64, 64), (5969, 1, 64, 64))\n"
     ]
    }
   ],
   "source": [
    "#Load data from hdf5\n",
    "import h5py\n",
    "\n",
    "hdf5_f = h5py.File(path + \"characters_base_64x64.hdf5\", mode='r')\n",
    "\n",
    "X = hdf5_f[\"X_curated_chars\"]\n",
    "y = hdf5_f[\"y_curated_chars\"]\n",
    "y_chars = np.array(y)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "\n",
    "char_select = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
    "               'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "\n",
    "X_train_u, y_train_u, X_test_u, y_test_u, decode_target_u = prepare_data_char_subset(X, y, char_select)\n",
    "print(X_train_u.shape, X_test_u.shape)\n",
    "\n",
    "char_select = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
    "               'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "X_train_l, y_train_l, X_test_l, y_test_l, decode_target_l = prepare_data_char_subset(X, y, char_select)\n",
    "print(X_train_l.shape, X_test_l.shape)\n",
    "\n",
    "hdf5_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z'}\n",
      "[[ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.38818359  1.          1.          0.01960754  0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]]\n",
      "[ 2  7 10 20 15]\n"
     ]
    }
   ],
   "source": [
    "print(decode_target_u)\n",
    "print(X_train_u[0,:,32,:])\n",
    "print(y_test_u[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Uppercase model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX TITAN Black (CNMeM is disabled, cuDNN 5103)\n",
      "/usr/local/lib/python2.7/dist-packages/theano/sandbox/cuda/__init__.py:599: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model 1...\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Uppercase model\n",
    "#\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "print('Build model 1...')\n",
    "input_images = Input(shape=(1, 64, 64))\n",
    "\n",
    "c11 = Convolution2D(64, 3, 3, border_mode='same', activation='relu')(input_images)\n",
    "c12 = Convolution2D(64, 3, 3, border_mode='same', activation='relu')(c11)\n",
    "c1_mp = MaxPooling2D((2, 2))(c12)\n",
    "\n",
    "c21 = Convolution2D(128, 3, 3, border_mode='same', activation='relu')(c1_mp)\n",
    "c22 = Convolution2D(128, 3, 3, border_mode='same', activation='relu')(c21)\n",
    "c2_mp = MaxPooling2D((2, 2))(c22)\n",
    "\n",
    "c31 = Convolution2D(256, 3, 3, border_mode='same', activation='relu')(c2_mp)\n",
    "c32 = Convolution2D(256, 3, 3, border_mode='same', activation='relu')(c31)\n",
    "c33 = Convolution2D(256, 3, 3, border_mode='same', activation='relu')(c32)\n",
    "c3_mp = MaxPooling2D((2, 2))(c33)\n",
    "\n",
    "conv_out = Flatten()(c3_mp)\n",
    "\n",
    "dense1 = Dense(1024, activation='relu')(conv_out)\n",
    "after_dp1 = Dropout(0.5)(dense1)\n",
    "\n",
    "dense2 = Dense(1024, activation='relu')(after_dp1)\n",
    "after_dp2 = Dropout(0.5)(dense2)\n",
    "\n",
    "output = Dense(26, activation='softmax')(after_dp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data augmentation in keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 15,       # 15ยบ of random rotation\n",
    "    width_shift_range = 0.20,  # 20% of random translation width\n",
    "    height_shift_range = 0.20, # 20% of random translation height\n",
    "    shear_range = 0.15,        # 5ยบ of shear\n",
    "    zoom_range = 0.20)         # +- 20% of zoom \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13005/13005 [==============================] - 42s - loss: 3.2193 - acc: 0.0734 - val_loss: 3.1313 - val_acc: 0.0781\n",
      "Epoch 2/100\n",
      "13005/13005 [==============================] - 47s - loss: 2.9292 - acc: 0.1614 - val_loss: 1.8011 - val_acc: 0.5391\n",
      "Epoch 3/100\n",
      "13005/13005 [==============================] - 47s - loss: 2.1690 - acc: 0.3561 - val_loss: 0.7979 - val_acc: 0.7808\n",
      "Epoch 4/100\n",
      "13005/13005 [==============================] - 47s - loss: 1.4647 - acc: 0.5491 - val_loss: 0.5146 - val_acc: 0.8604\n",
      "Epoch 5/100\n",
      "13005/13005 [==============================] - 47s - loss: 1.1181 - acc: 0.6577 - val_loss: 0.3541 - val_acc: 0.9182\n",
      "Epoch 6/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.9203 - acc: 0.7171 - val_loss: 0.2613 - val_acc: 0.9311\n",
      "Epoch 7/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.7777 - acc: 0.7639 - val_loss: 0.2218 - val_acc: 0.9413\n",
      "Epoch 8/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.7259 - acc: 0.7817 - val_loss: 0.2100 - val_acc: 0.9419\n",
      "Epoch 9/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.6575 - acc: 0.7973 - val_loss: 0.1841 - val_acc: 0.9462\n",
      "Epoch 10/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.6030 - acc: 0.8141 - val_loss: 0.1619 - val_acc: 0.9523\n",
      "Epoch 11/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.5712 - acc: 0.8275 - val_loss: 0.1680 - val_acc: 0.9551\n",
      "Epoch 12/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.5593 - acc: 0.8298 - val_loss: 0.1538 - val_acc: 0.9566\n",
      "Epoch 13/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.5260 - acc: 0.8398 - val_loss: 0.1347 - val_acc: 0.9600\n",
      "Epoch 14/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.4977 - acc: 0.8507 - val_loss: 0.1348 - val_acc: 0.9606\n",
      "Epoch 15/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.4825 - acc: 0.8543 - val_loss: 0.1248 - val_acc: 0.9600\n",
      "Epoch 16/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.4522 - acc: 0.8633 - val_loss: 0.1197 - val_acc: 0.9643\n",
      "Epoch 17/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.4450 - acc: 0.8617 - val_loss: 0.1171 - val_acc: 0.9677\n",
      "Epoch 18/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.4411 - acc: 0.8640 - val_loss: 0.1169 - val_acc: 0.9649\n",
      "Epoch 19/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.4198 - acc: 0.8740 - val_loss: 0.1088 - val_acc: 0.9683\n",
      "Epoch 20/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.4054 - acc: 0.8743 - val_loss: 0.1082 - val_acc: 0.9680\n",
      "Epoch 21/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.4103 - acc: 0.8752 - val_loss: 0.1065 - val_acc: 0.9692\n",
      "Epoch 22/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.3790 - acc: 0.8823 - val_loss: 0.0986 - val_acc: 0.9726\n",
      "Epoch 23/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.3778 - acc: 0.8866 - val_loss: 0.0967 - val_acc: 0.9720\n",
      "Epoch 24/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.3779 - acc: 0.8871 - val_loss: 0.1003 - val_acc: 0.9708\n",
      "Epoch 25/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.3615 - acc: 0.8872 - val_loss: 0.0947 - val_acc: 0.9726\n",
      "Epoch 26/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.3416 - acc: 0.8974 - val_loss: 0.0958 - val_acc: 0.9705\n",
      "Epoch 27/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.3454 - acc: 0.8922 - val_loss: 0.0865 - val_acc: 0.9717\n",
      "Epoch 28/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.3572 - acc: 0.8894 - val_loss: 0.0936 - val_acc: 0.9723\n",
      "Epoch 29/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.3463 - acc: 0.8943 - val_loss: 0.0879 - val_acc: 0.9742\n",
      "Epoch 30/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.3392 - acc: 0.8959 - val_loss: 0.0832 - val_acc: 0.9732\n",
      "Epoch 31/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.3455 - acc: 0.8952 - val_loss: 0.0857 - val_acc: 0.9754\n",
      "Epoch 32/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.3332 - acc: 0.8974 - val_loss: 0.0869 - val_acc: 0.9748\n",
      "Epoch 33/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.3269 - acc: 0.9007 - val_loss: 0.0857 - val_acc: 0.9769\n",
      "Epoch 34/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.3256 - acc: 0.8995 - val_loss: 0.0850 - val_acc: 0.9757\n",
      "Epoch 35/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.3157 - acc: 0.9042 - val_loss: 0.0817 - val_acc: 0.9782\n",
      "Epoch 36/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.3124 - acc: 0.9062 - val_loss: 0.0838 - val_acc: 0.9751\n",
      "Epoch 37/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2992 - acc: 0.9062 - val_loss: 0.0892 - val_acc: 0.9736\n",
      "Epoch 38/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.3112 - acc: 0.9056 - val_loss: 0.0803 - val_acc: 0.9772\n",
      "Epoch 39/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.3043 - acc: 0.9070 - val_loss: 0.0817 - val_acc: 0.9763\n",
      "Epoch 40/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2943 - acc: 0.9120 - val_loss: 0.0819 - val_acc: 0.9763\n",
      "Epoch 41/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2923 - acc: 0.9079 - val_loss: 0.0857 - val_acc: 0.9745\n",
      "Epoch 42/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2938 - acc: 0.9125 - val_loss: 0.0819 - val_acc: 0.9751\n",
      "Epoch 43/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2992 - acc: 0.9095 - val_loss: 0.0718 - val_acc: 0.9803\n",
      "Epoch 44/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2870 - acc: 0.9132 - val_loss: 0.0804 - val_acc: 0.9763\n",
      "Epoch 45/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2865 - acc: 0.9137 - val_loss: 0.0802 - val_acc: 0.9763\n",
      "Epoch 46/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2844 - acc: 0.9118 - val_loss: 0.0727 - val_acc: 0.9800\n",
      "Epoch 47/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2786 - acc: 0.9157 - val_loss: 0.0762 - val_acc: 0.9779\n",
      "Epoch 48/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2635 - acc: 0.9183 - val_loss: 0.0760 - val_acc: 0.9776\n",
      "Epoch 49/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2719 - acc: 0.9182 - val_loss: 0.0722 - val_acc: 0.9782\n",
      "Epoch 50/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2809 - acc: 0.9140 - val_loss: 0.0796 - val_acc: 0.9776\n",
      "Epoch 51/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2738 - acc: 0.9147 - val_loss: 0.0710 - val_acc: 0.9772\n",
      "Epoch 52/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2703 - acc: 0.9171 - val_loss: 0.0748 - val_acc: 0.9782\n",
      "Epoch 53/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2661 - acc: 0.9187 - val_loss: 0.0755 - val_acc: 0.9776\n",
      "Epoch 54/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2692 - acc: 0.9183 - val_loss: 0.0735 - val_acc: 0.9776\n",
      "Epoch 55/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2647 - acc: 0.9206 - val_loss: 0.0692 - val_acc: 0.9788\n",
      "Epoch 56/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2610 - acc: 0.9200 - val_loss: 0.0718 - val_acc: 0.9788\n",
      "Epoch 57/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2569 - acc: 0.9222 - val_loss: 0.0694 - val_acc: 0.9800\n",
      "Epoch 58/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2476 - acc: 0.9245 - val_loss: 0.0712 - val_acc: 0.9797\n",
      "Epoch 59/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2559 - acc: 0.9216 - val_loss: 0.0696 - val_acc: 0.9809\n",
      "Epoch 60/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2492 - acc: 0.9221 - val_loss: 0.0672 - val_acc: 0.9822\n",
      "Epoch 61/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2535 - acc: 0.9235 - val_loss: 0.0703 - val_acc: 0.9791\n",
      "Epoch 62/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2533 - acc: 0.9233 - val_loss: 0.0660 - val_acc: 0.9785\n",
      "Epoch 63/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2494 - acc: 0.9227 - val_loss: 0.0670 - val_acc: 0.9809\n",
      "Epoch 64/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2415 - acc: 0.9243 - val_loss: 0.0725 - val_acc: 0.9794\n",
      "Epoch 65/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2489 - acc: 0.9209 - val_loss: 0.0691 - val_acc: 0.9812\n",
      "Epoch 66/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2516 - acc: 0.9232 - val_loss: 0.0725 - val_acc: 0.9791\n",
      "Epoch 67/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2374 - acc: 0.9261 - val_loss: 0.0699 - val_acc: 0.9809\n",
      "Epoch 68/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2375 - acc: 0.9262 - val_loss: 0.0658 - val_acc: 0.9825\n",
      "Epoch 69/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2404 - acc: 0.9243 - val_loss: 0.0672 - val_acc: 0.9803\n",
      "Epoch 70/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2434 - acc: 0.9239 - val_loss: 0.0648 - val_acc: 0.9800\n",
      "Epoch 71/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2270 - acc: 0.9265 - val_loss: 0.0673 - val_acc: 0.9782\n",
      "Epoch 72/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2373 - acc: 0.9264 - val_loss: 0.0654 - val_acc: 0.9812\n",
      "Epoch 73/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2457 - acc: 0.9243 - val_loss: 0.0652 - val_acc: 0.9812\n",
      "Epoch 74/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2304 - acc: 0.9290 - val_loss: 0.0639 - val_acc: 0.9825\n",
      "Epoch 75/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2419 - acc: 0.9252 - val_loss: 0.0680 - val_acc: 0.9822\n",
      "Epoch 76/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2329 - acc: 0.9300 - val_loss: 0.0651 - val_acc: 0.9815\n",
      "Epoch 77/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2408 - acc: 0.9232 - val_loss: 0.0647 - val_acc: 0.9809\n",
      "Epoch 78/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2320 - acc: 0.9271 - val_loss: 0.0704 - val_acc: 0.9806\n",
      "Epoch 79/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2423 - acc: 0.9266 - val_loss: 0.0639 - val_acc: 0.9794\n",
      "Epoch 80/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2292 - acc: 0.9309 - val_loss: 0.0651 - val_acc: 0.9825\n",
      "Epoch 81/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2297 - acc: 0.9282 - val_loss: 0.0673 - val_acc: 0.9800\n",
      "Epoch 82/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2230 - acc: 0.9347 - val_loss: 0.0653 - val_acc: 0.9819\n",
      "Epoch 83/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2255 - acc: 0.9300 - val_loss: 0.0683 - val_acc: 0.9822\n",
      "Epoch 84/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2251 - acc: 0.9292 - val_loss: 0.0636 - val_acc: 0.9834\n",
      "Epoch 85/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2258 - acc: 0.9303 - val_loss: 0.0620 - val_acc: 0.9809\n",
      "Epoch 86/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2358 - acc: 0.9253 - val_loss: 0.0636 - val_acc: 0.9825\n",
      "Epoch 87/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2252 - acc: 0.9306 - val_loss: 0.0652 - val_acc: 0.9825\n",
      "Epoch 88/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2168 - acc: 0.9335 - val_loss: 0.0625 - val_acc: 0.9809\n",
      "Epoch 89/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2118 - acc: 0.9315 - val_loss: 0.0658 - val_acc: 0.9822\n",
      "Epoch 90/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2191 - acc: 0.9339 - val_loss: 0.0603 - val_acc: 0.9819\n",
      "Epoch 91/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2262 - acc: 0.9298 - val_loss: 0.0616 - val_acc: 0.9819\n",
      "Epoch 92/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2198 - acc: 0.9325 - val_loss: 0.0653 - val_acc: 0.9834\n",
      "Epoch 93/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2129 - acc: 0.9339 - val_loss: 0.0621 - val_acc: 0.9828\n",
      "Epoch 94/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2215 - acc: 0.9283 - val_loss: 0.0669 - val_acc: 0.9812\n",
      "Epoch 95/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2175 - acc: 0.9339 - val_loss: 0.0648 - val_acc: 0.9819\n",
      "Epoch 96/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2139 - acc: 0.9326 - val_loss: 0.0628 - val_acc: 0.9825\n",
      "Epoch 97/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2232 - acc: 0.9292 - val_loss: 0.0628 - val_acc: 0.9825\n",
      "Epoch 98/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2103 - acc: 0.9359 - val_loss: 0.0612 - val_acc: 0.9828\n",
      "Epoch 99/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2131 - acc: 0.9341 - val_loss: 0.0623 - val_acc: 0.9822\n",
      "Epoch 100/100\n",
      "13005/13005 [==============================] - 47s - loss: 0.2190 - acc: 0.9320 - val_loss: 0.0603 - val_acc: 0.9837\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model_u = Model(input=input_images, output=output)\n",
    "\n",
    "#Fit model  on batches with real-time data augmentation:\n",
    "sgd = SGD(lr=0.01, decay=0.001, momentum=0.9, nesterov=True)\n",
    "model_u.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "hist_u_1 = model_u.fit_generator(datagen.flow(X_train_u, y_train_u, batch_size=128),\n",
    "                    samples_per_epoch=len(X_train_u), nb_epoch=100, \n",
    "                    validation_data=(X_test_u, y_test_u))\n",
    "\n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy for UNIPEN upper case: 98.4%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2936dc3c50>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlcAAAJPCAYAAABRvvFyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAAAAAAAAAAAAAABAff8fRKRzVF/wTasAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f295ee91bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist_u_1.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Save model\n",
    "path_models = '/home/jorge/data/tesis/handwriting/p01_read_character/'\n",
    "\n",
    "model_name = 'unipen_uppercase_01'\n",
    "\n",
    "json_string = model_u.to_json()\n",
    "open(path_models + 'models/mdl_' + model_name + '.json', 'w').write(json_string)\n",
    "model_u.save_weights(path_models + 'models/w_' + model_name + '.h5', overwrite=True)\n",
    "\n",
    "# Save decode_target\n",
    "import pickle\n",
    "pickle.dump( decode_target_u, open( path_models + \"models/unipen_decode_target_uppercase.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Use the model trained to score the TICH dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "model_name = 'unipen_uppercase_01'\n",
    "\n",
    "model_u = model_from_json(open(path_models + 'models/mdl_' + model_name + '.json').read())\n",
    "model_u.load_weights(path_models + 'models/w_' + model_name + '.h5')\n",
    "\n",
    "# Load the dictionary back from the pickle file.\n",
    "import pickle\n",
    "decode_target = pickle.load( open(path_models + \"models/unipen_decode_target_uppercase.p\", \"rb\" ) )\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read TICH\n",
    "path_TICH = '/home/jorge/data/tesis/handwriting/databases/TICH/digits/'\n",
    "\n",
    "labels = pd.read_csv(path_TICH + 'labels.txt', header=None, names=['target'])\n",
    "train  = pd.read_csv(path_TICH + 'train.txt', header=None, delimiter=' ', names=['file','target_code'])\n",
    "valid  = pd.read_csv(path_TICH + 'valid.txt', header=None, delimiter=' ', names=['file','target_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select uppercase, target code: >=10\n",
    "# Create X_train(image 64x64), Y_train(sparse target 26 ), X_valid y_valid\n",
    "# Not X. Put it -->  Recode target t = tc-10 if tc<33 else t=tc-9\n",
    "\n",
    "def exctrac_TICH(ds):\n",
    "    X_TICH = []\n",
    "    y_TICH = []\n",
    "    for i,row in train[:].iterrows():\n",
    "        if row.target_code>=10:\n",
    "            img_name = row.file.split('/')[-1]\n",
    "            img = plt.imread(path_TICH + 'imgs/'+img_name)\n",
    "            X_TICH += [img]\n",
    "            y_TICH += [row.target_code-10 if row.target_code<33 else row.target_code-9]\n",
    "\n",
    "    return np.array(X_TICH), np.array(y_TICH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29186, 64, 64)\n",
      "(29186,)\n"
     ]
    }
   ],
   "source": [
    "X_TICH_trn, y_TICH_trn = exctrac_TICH(train)\n",
    "\n",
    "print(X_TICH_trn.shape)\n",
    "print(y_TICH_trn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29186, 64, 64)\n",
      "(29186,)\n"
     ]
    }
   ],
   "source": [
    "X_TICH_val, y_TICH_val = exctrac_TICH(valid)\n",
    "\n",
    "print(X_TICH_val.shape)\n",
    "print(y_TICH_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.00392157  0.00784314\n",
      "  0.03921569  0.08627451  0.13333334  0.35686275  0.5529412   0.67058825\n",
      "  0.74117649  0.81176472  0.8509804   0.72549021  0.57254905  0.37254903\n",
      "  0.07843138  0.01960784  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(X_TICH_trn[0,12,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = model_u.predict(X_TICH_trn[0:10].reshape((10, 1, 64, 64)), batch_size=10)\n",
    "print y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  3  7  0 17  3 11  4 18  3]\n"
     ]
    }
   ],
   "source": [
    "print(y_TICH_val[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29186, 26)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_u.predict(X_TICH_trn.reshape((29186, 1, 64, 64)), batch_size=128)\n",
    "print(y_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.925786335914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_TICH_val, np.argmax(y_pred, axis=1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Accuracy for TICH database: 0.9258"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the previous created model to score NIST database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "Z\n",
      "{0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z'}\n",
      "{0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z'}\n"
     ]
    }
   ],
   "source": [
    "#Read NIST dataset \n",
    "path_NIST='/home/jorge/data/tesis/handwriting/databases/NIST/by_class/'\n",
    "\n",
    "\n",
    "char_list_up = ['41','42','43','44','45','46','47','48','49','4a','4b','4c','4d',\n",
    "                '4e','4f','50','51','52','53','54','55','56','57','58','59','5a']\n",
    "           \n",
    "char_list_lo = ['61','62','63','64','65','66','67','68','69','6a','6b','6c','6d'\n",
    "               ,'6e','6f','70','71','72','73','74','75','76','77','78','79','7a']\n",
    "\n",
    "print(str(unichr(int('41',16))))\n",
    "print(str(unichr(int('5a',16))))\n",
    "\n",
    "decode_up={}\n",
    "encode_up={}\n",
    "for i , c in enumerate(char_list_up):\n",
    "    char = str(unichr(int(c,16)))\n",
    "    decode_up[i] = char\n",
    "    encode_up[char] = i\n",
    "print decode_up               \n",
    "\n",
    "\n",
    "decode_lo={}\n",
    "encode_lo={}\n",
    "for i , c in enumerate(char_list_lo):\n",
    "    char = str(unichr(int(c,16)))\n",
    "    decode_lo[i] = char\n",
    "    encode_lo[char] = i\n",
    "print decode_lo               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generator of list of files in a folder and subfolders\n",
    "import os\n",
    "import shutil\n",
    "import fnmatch\n",
    "\n",
    "def gen_find(filepat,top):\n",
    "    for path, dirlist, filelist in os.walk(top):\n",
    "        for name in fnmatch.filter(filelist,filepat):\n",
    "            yield os.path.join(path,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11941, 64, 64)\n",
      "(11941,)\n"
     ]
    }
   ],
   "source": [
    "hsf='/hsf_4/'\n",
    "\n",
    "#Read test dataset\n",
    "X_NIST_up=[]\n",
    "y_NIST_up=[]\n",
    "for char in char_list_up:\n",
    "    letter = str(unichr(int(char,16)))\n",
    "    images_list = gen_find(\"*.png\", path_NIST+char+hsf) \n",
    "    for img_name in images_list:\n",
    "        img = plt.imread(img_name)\n",
    "        \n",
    "        #Transform\n",
    "        img = img[32:96,32:96,0]\n",
    "        \n",
    "        X_NIST_up += [img]\n",
    "        y_NIST_up += [encode_up[letter]]\n",
    "\n",
    "X_NIST_up = 1. - np.array(X_NIST_up)\n",
    "y_NIST_up = np.array(y_NIST_up)\n",
    "        \n",
    "print(X_NIST_up.shape)\n",
    "print(y_NIST_up.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(X_NIST_up[0,32,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11941, 26)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_u.predict(X_NIST_up.reshape((11941, 1, 64, 64)), batch_size=128)\n",
    "print(y_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92915166234\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_NIST_up, np.argmax(y_pred, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Accuracy for NIST database (2nd ed) upper case: 92,9%\n",
    "    - The low score can be explained because the NIST database is binary (pixels only 0 or 1).\n",
    "    - We need to train the same architecture over the NIST database in order to obtain a better comparation to others."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
